{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "20ee3377-6019-4e36-acc7-9a8e3a2429f4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Process Addresses data in PySpark\n",
    "1. Ingest the data into the data kalehouse : bronze_addresses\n",
    "2. perform data quality checks and transform the data as required : silver_addresses_clean\n",
    "3. Apply changes to the Addresses data (SCD Type 2) : silver_addresses\n",
    "4. Since in DLT notebooks, we cannont use multiple languages in one notebook, we cannot use magic command"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0fd4e2b4-9c12-4447-a9a7-f7ff0a41fe17",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###1. Ingest the data into the data kalehouse : bronze_addresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dbf70a4f-f7e5-4c17-8a99-b1c7729ffe73",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import dlt\n",
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9d5158a4-8267-41c5-b08a-344ee491583c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# In python to invoke autoloader, we use .format(\"cloudFiles\")\n",
    "# In SQL, we use the format \"cloudFiles()\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9f28291a-a3c5-4a12-b594-44552f4c65d7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# CREATING DELTA LIVE TABLES in Python\n",
    "@dlt.table(\n",
    "    name=\"bronze_addresses\",\n",
    "    table_properties={'quality' : 'bronze'},\n",
    "    comment=\"Raw addresses data ingested from the source system\"\n",
    ")\n",
    "def bronze_addresses();\n",
    "  return (\n",
    "    spark.readStream.format(\"cloudFiles\")\n",
    "                    .option(\"cloudFiles.format\", \"csv\")\n",
    "                    .option(\"cloudFiles.inferColumnTypes\", True)\n",
    "                    .load(\"/Volumes/circuitbox/landing/operational_data/addresses/\")\n",
    "                    .select(\n",
    "                            *,\n",
    "                            F.col(\"_metadata.file_path\").alias(\"file_path\"), #Adding new column1\n",
    "                            F.current_timestamp().alias(\"ingest_timestamp\")  #Adding new column2\n",
    "                    )\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d928f968-f1b4-446d-a37a-5bae95801239",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###2. Perform data quality checks and transform the data as required : silver_addresses_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cf1fcadf-2248-4f08-9a84-c60d4a4d3a05",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "@dlt.table(\n",
    "    name=\"silver_addresses_clean\",\n",
    "    table_properties={'quality' : 'silver'},\n",
    "    comment=\"Cleaned addresses data ingested from the bronze_addresses table\",\n",
    ")\n",
    "@dlt.expect_or_fail(\"valid_customer_id\", \"customer_id IS NOT NULL\")\n",
    "@dlt.expect_or_drop(\"valid_address_line_1\", \"address_line_1 IS NOT NULL\")\n",
    "@dlt.expect(\"valid_postcode\", \"LENGTH(postcode) = 5\")\n",
    "def silver_addresses_clean():\n",
    "  return (\n",
    "          spark.readStream.table(\"bronze_addresses\")\n",
    "               .select(\n",
    "                     \"customer_id\",\n",
    "                     \"address_line_1\",\n",
    "                     \"city\",\n",
    "                     \"state\",\n",
    "                     \"postcode\",\n",
    "                     F.col(\"created_date\").cast(\"date\")                     \n",
    "               )\n",
    "  )\n",
    "         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "49db5e3a-f5ed-42f4-be4c-c8991fd26293",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###3. Apply changes to the Addresses data (SCD Type 2) : silver_addresses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d258185d-0eee-417b-a2a1-4f146b3a922f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##### To Create SCT Type 2, I am using APPLY CHANGES API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "219cb6cb-510e-4c79-845c-0f79338b931d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Since APPLY CHANGES API doesnot create table, we need to create it upfront\n",
    "\n",
    "dlt.create_streaming_table(\n",
    "     name = \"silver_addresses\",\n",
    "     comment = \"SCD Type 2 addresses data\",\n",
    "     tbl_properties = {'quality' : 'silver'}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cfa0daac-3ce0-430c-9fcf-ecc97b2cec4c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Using APPLY CHANGES API to make the table SCD Type 2\n",
    "\n",
    "dlt.apply_changes(\n",
    "    target = \"silver_addresses\",\n",
    "    source = \"silver_addresses_clean\",\n",
    "    keys = [\"customer_id\"],\n",
    "    sequence_by = \"created_date\",\n",
    "    stored_as_scd_type_2 = True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "03.Process_Addresses_Data_in_Python",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}